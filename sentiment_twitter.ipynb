{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting snscrape\n",
      "  Downloading snscrape-0.7.0.20230622-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from snscrape) (2.31.0)\n",
      "Collecting lxml (from snscrape)\n",
      "  Downloading lxml-5.3.1-cp38-cp38-win_amd64.whl.metadata (3.6 kB)\n",
      "Collecting beautifulsoup4 (from snscrape)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from snscrape)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from snscrape) (2024.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->snscrape)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from beautifulsoup4->snscrape) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from requests[socks]->snscrape) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from requests[socks]->snscrape) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from requests[socks]->snscrape) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages (from requests[socks]->snscrape) (2024.2.2)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->snscrape)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.8 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.8 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 61.4/74.8 kB 825.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 74.8/74.8 kB 827.9 kB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "   ---------------------------------------- 0.0/186.0 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 61.4/186.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 112.6/186.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 186.0/186.0 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading lxml-5.3.1-cp38-cp38-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 2.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/3.8 MB 2.2 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/3.8 MB 1.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.4/3.8 MB 1.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.5/3.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 0.6/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.7/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.7/3.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.8/3.8 MB 1.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.8/3.8 MB 1.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.2/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.2/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.3/3.8 MB 1.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.4/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.4/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.5/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.7/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.8/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.8/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.9/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.0/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.0/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.1/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 1.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.3/3.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.3/3.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.3/3.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.3/3.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.4/3.8 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.4/3.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.4/3.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.4/3.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.4/3.8 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.5/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.5/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.5/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.5/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 2.6/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.6/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.6/3.8 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.7/3.8 MB 1.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 2.7/3.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.8/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.9/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.0/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.2/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, PySocks, lxml, filelock, beautifulsoup4, snscrape\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.13.3 filelock-3.16.1 lxml-5.3.1 snscrape-0.7.0.20230622 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install snscrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment using Snscrape (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AAPL%20stock%20since%3A2025-02-27%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
      "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AAPL%20stock%20since%3A2025-02-27%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
      "Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AAPL%20stock%20since%3A2025-02-27%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\naush\\main\\Resume\\jan 2024\\feb\\New folder\\coursewrork\\StockPriceAnalyzer\\sentiment_twitter.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(tweet_list[:count])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Example: Fetch tweets for AAPL\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m tweets_df \u001b[39m=\u001b[39m scrape_tweets(\u001b[39m\"\u001b[39;49m\u001b[39mAAPL\u001b[39;49m\u001b[39m\"\u001b[39;49m, count\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Save to Parquet\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m tweets_df\u001b[39m.\u001b[39mto_parquet(\u001b[39m\"\u001b[39m\u001b[39mTwitter_News.parquet\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\naush\\main\\Resume\\jan 2024\\feb\\New folder\\coursewrork\\StockPriceAnalyzer\\sentiment_twitter.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstock_symbol\u001b[39m}\u001b[39;00m\u001b[39m stock since:2025-02-27\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tweets \u001b[39m=\u001b[39m sntwitter\u001b[39m.\u001b[39mTwitterSearchScraper(query)\u001b[39m.\u001b[39mget_items()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tweet_list \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mcreated_at\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mdate} \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(tweet_list[:count])\n",
      "\u001b[1;32mc:\\Users\\naush\\main\\Resume\\jan 2024\\feb\\New folder\\coursewrork\\StockPriceAnalyzer\\sentiment_twitter.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstock_symbol\u001b[39m}\u001b[39;00m\u001b[39m stock since:2025-02-27\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tweets \u001b[39m=\u001b[39m sntwitter\u001b[39m.\u001b[39mTwitterSearchScraper(query)\u001b[39m.\u001b[39mget_items()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tweet_list \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mcreated_at\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mdate} \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m tweets]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/naush/main/Resume/jan%202024/feb/New%20folder/coursewrork/StockPriceAnalyzer/sentiment_twitter.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(tweet_list[:count])\n",
      "File \u001b[1;32mc:\\Users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages\\snscrape\\modules\\twitter.py:1763\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1760\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m'\u001b[39m: variables, \u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m: features}\n\u001b[0;32m   1761\u001b[0m paginationParams \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m'\u001b[39m: paginationVariables, \u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m: features}\n\u001b[1;32m-> 1763\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline\u001b[39m\u001b[39m'\u001b[39m, _TwitterAPIType\u001b[39m.\u001b[39mGRAPHQL, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor, instructionsPath \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msearch_by_raw_query\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msearch_timeline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtimeline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstructions\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m   1764\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graphql_timeline_instructions_to_tweets(obj[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msearch_by_raw_query\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msearch_timeline\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtimeline\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39minstructions\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages\\snscrape\\modules\\twitter.py:915\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 915\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, apiType, reqParams, instructionsPath \u001b[39m=\u001b[39;49m instructionsPath)\n\u001b[0;32m    916\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    918\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages\\snscrape\\modules\\twitter.py:886\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m apiType \u001b[39mis\u001b[39;00m _TwitterAPIType\u001b[39m.\u001b[39mGRAPHQL:\n\u001b[0;32m    885\u001b[0m \tparams \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39murlencode({k: json\u001b[39m.\u001b[39mdumps(v, separators \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()}, quote_via \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39mquote)\n\u001b[1;32m--> 886\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m functools\u001b[39m.\u001b[39;49mpartial(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response, apiType \u001b[39m=\u001b[39;49m apiType, instructionsPath \u001b[39m=\u001b[39;49m instructionsPath))\n\u001b[0;32m    887\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39m_snscrapeObj\n",
      "File \u001b[1;32mc:\\Users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages\\snscrape\\base.py:275\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 275\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\naush\\anaconda3\\envs\\py38\\lib\\site-packages\\snscrape\\base.py:271\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[0;32m    269\u001b[0m \t_logger\u001b[39m.\u001b[39mfatal(msg)\n\u001b[0;32m    270\u001b[0m \t_logger\u001b[39m.\u001b[39mfatal(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mErrors: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(errors)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 271\u001b[0m \t\u001b[39mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    272\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mReached unreachable code\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22AAPL%20stock%20since%3A2025-02-27%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape tweets\n",
    "def scrape_tweets(stock_symbol, count=10):\n",
    "    query = f\"{stock_symbol} stock since:2025-02-27\"\n",
    "    tweets = sntwitter.TwitterSearchScraper(query).get_items()\n",
    "    \n",
    "    tweet_list = [{\"text\": tweet.content, \"created_at\": tweet.date} for tweet in tweets]\n",
    "    return pd.DataFrame(tweet_list[:count])\n",
    "\n",
    "# Example: Fetch tweets for AAPL\n",
    "tweets_df = scrape_tweets(\"AAPL\", count=10)\n",
    "\n",
    "# Save to Parquet\n",
    "tweets_df.to_parquet(\"Twitter_News.parquet\", index=False)\n",
    "\n",
    "# Display first few tweets\n",
    "print(tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
